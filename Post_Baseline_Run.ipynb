{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for the purpose of running the `distillbert base uncased emotion` model hosted on huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name bhadresh-savani/distilbert-base-uncased-emotion. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('bhadresh-savani/distilbert-base-uncased-emotion')\n",
    "model = SentenceTransformer('bhadresh-savani/distilbert-base-uncased-emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean emotion filtered data shape:  (27981, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1287_153_9</td>\n",
       "      <td>I mean what the hell bro.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_1287_187_0</td>\n",
       "      <td>Yeah, crazy isn't it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_1287_204_0</td>\n",
       "      <td>No :( sadly it doesn't have everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_1287_222_4</td>\n",
       "      <td>I'm worried.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_1287_240_1</td>\n",
       "      <td>Better weapons and going against a weaker team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          docid                                               TEXT\n",
       "0  s_1287_153_9                          I mean what the hell bro.\n",
       "1  s_1287_187_0                              Yeah, crazy isn't it?\n",
       "2  s_1287_204_0           No :( sadly it doesn't have everything  \n",
       "3  s_1287_222_4                                       I'm worried.\n",
       "4  s_1287_240_1  Better weapons and going against a weaker team..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "clean_ef_data = pd.read_csv('tabulated_cleaned_emotionfiltered_trec.csv')\n",
    "clean_ef_data = clean_ef_data.drop(['polarity', 'self_ref', 'PRE', 'POST'], axis=1)\n",
    "print(\"clean emotion filtered data shape: \", clean_ef_data.shape)\n",
    "clean_ef_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aug answer set shape:  (928, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>I feel guilty a significant amount of time</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>691</th>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>I am experiencing sleep disruption in the ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>My crying frequency is normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>I’m sad all the time and can’t recover from it</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question  Severity                                               Text\n",
       "195         5         2         I feel guilty a significant amount of time\n",
       "691        16         3   I am experiencing sleep disruption in the ear...\n",
       "403        10         1                      My crying frequency is normal\n",
       "26          1         3     I’m sad all the time and can’t recover from it"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load set of augmented answers\n",
    "aug_answer_set = pd.read_csv('augmented_answer_sets.csv')\n",
    "print(\"aug answer set shape: \", aug_answer_set.shape)\n",
    "aug_answer_set.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have answer sets and input text, let's create embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672b6154bc4a48c5b49c616a1a73a016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create tokens and vector embeddings for user posts\n",
    "post_embeddings_df = clean_ef_data.copy()\n",
    "\n",
    "post_embeddings = post_embeddings_df['TEXT'].to_list()\n",
    "\n",
    "post_embeddings = model.encode(post_embeddings, device='cuda', show_progress_bar=True, \n",
    "                               output_value='sentence_embedding', convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 51.39it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store the embeddings\n",
    "bdi_embeddings = {}\n",
    "\n",
    "# Loop over all 21 BDI questions\n",
    "for i in tqdm(range(1, 22), total=21):\n",
    "    # Filter the DataFrame for the current question and severity > 1\n",
    "    bdi_i_embedding_df = aug_answer_set[(aug_answer_set['Question'] == i) & (aug_answer_set['Severity'] > 1)]\n",
    "    \n",
    "    # Get embeddings for the filtered DataFrame\n",
    "    bdi_i_embeddings = model.encode(\n",
    "        bdi_i_embedding_df['Text'].to_list(), device='cuda', output_value='sentence_embedding', convert_to_tensor=True\n",
    "    )\n",
    "    \n",
    "    # Store the embeddings in the dictionary\n",
    "    bdi_embeddings[f\"q{i}\"] = bdi_i_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have embeddings for each post and the associated question, we will rank. \n",
    "\n",
    "The rankings will be computed for each question, and are based on the max-similarity \n",
    "\n",
    "between a post's embedding and the embedding array of the corresponding question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27981/27981 [00:05<00:00, 5318.71it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5211.33it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5179.95it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5187.73it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5291.09it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5075.12it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5194.21it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5184.15it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5144.95it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5175.53it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5145.93it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5163.96it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5214.69it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5019.44it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5133.86it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5127.80it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5111.37it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5129.58it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5126.15it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5121.33it/s]\n",
      "100%|██████████| 27981/27981 [00:05<00:00, 5212.61it/s]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_dict = {}\n",
    "\n",
    "for i in range(1, 22):\n",
    "\n",
    "    # Get the correct embeddings list by key\n",
    "    qa_embeddings = bdi_embeddings[f\"q{i}\"]\n",
    "\n",
    "    # Get the max cosine similarity between each post embedding and the answer set for the current BDI question\n",
    "    qi_cos_similarities = [\n",
    "        torch.max(cosine_similarity(post_embedding, qa_embeddings)).item()\n",
    "        for post_embedding in tqdm(post_embeddings, total=len(post_embeddings))\n",
    "    ]\n",
    "\n",
    "    # Assign these max cosine similarity rankings to the cosine similarity dictionary\n",
    "    cosine_similarity_dict[f'q{i}'] = qi_cos_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cosine similarities for each question, we need to assign them post ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 136.55it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store the rankings for each question\n",
    "rankings_dict = {}\n",
    "\n",
    "# Loop over all 21 BDI questions\n",
    "for i in tqdm(range(1, 22), total=21):\n",
    "    # Make a copy of the clean_ef_data DataFrame\n",
    "    q_rankings = clean_ef_data.copy()\n",
    "    \n",
    "    # Add a 'score' column to the DataFrame, which contains the cosine similarity scores for the current question\n",
    "    q_rankings['score'] = cosine_similarity_dict[f'q{i}']\n",
    "    \n",
    "    # Sort the DataFrame by the 'score' column in descending order and reset the index\n",
    "    q_rankings = q_rankings.sort_values('score', ascending=False, ignore_index=True)\n",
    "    \n",
    "    # Keep only the top 1000 rows\n",
    "    q_rankings = q_rankings.head(1000)\n",
    "    \n",
    "    # Store the DataFrame in the rankings_dict dictionary with the key as the current question\n",
    "    rankings_dict[f'q{i}'] = q_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the rankings dict as trec-formatted content before saving to disk.\n",
    "for i, key in enumerate(rankings_dict.keys()):\n",
    "    rankings_dict[key]['query'] = f'{i+1}' # create query number\n",
    "    rankings_dict[key]['q_id'] = rankings_dict[key]['query']\n",
    "    rankings_dict[key]['doc_id'] = rankings_dict[key]['docid']\n",
    "    rankings_dict[key]['q0'] = '0'\n",
    "    rankings_dict[key]['rank'] = range(1, 1001)\n",
    "    rankings_dict[key]['rank'] = rankings_dict[key]['rank'].astype(str)\n",
    "    rankings_dict[key]['model'] = 'distilbert-base-uncased-emotion'\n",
    "    rankings_dict[key] = rankings_dict[key][[\"q_id\", \"q0\", \"doc_id\", \"score\", \"rank\", \"model\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, df in rankings_dict.items():\n",
    "#     df.to_csv(f'distilbert-base-uncased-ranking-outputs/{key}_rankings.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate all the DataFrames in the dictionary\n",
    "all_rankings = pd.concat(rankings_dict.values(), ignore_index=True)\n",
    "\n",
    "# # Save the concatenated DataFrame as a TSV file\n",
    "all_rankings.to_csv('distilbert_mod_results.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have completed the rankings portion for our fine-tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
