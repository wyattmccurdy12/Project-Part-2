{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is for the purpose of running the `distillbert base uncased emotion` model hosted on huggingface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import torch\n",
    "import os\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # FINETUNED VERSION\n",
    "# # Load model directly\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertModel\n",
    "# from transformers import DistilBertModel, DistilBertTokenizer\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# tokenizer = DistilBertTokenizer.from_pretrained('bhadresh-savani/distilbert-base-uncased-emotion')\n",
    "# model = SentenceTransformer('bhadresh-savani/distilbert-base-uncased-emotion')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # BASE VERSION\n",
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, BertTokenizer, BertModel\n",
    "from transformers import DistilBertModel, DistilBertTokenizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean emotion filtered data shape:  (27981, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>docid</th>\n",
       "      <th>TEXT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>s_1287_153_9</td>\n",
       "      <td>I mean what the hell bro.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>s_1287_187_0</td>\n",
       "      <td>Yeah, crazy isn't it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>s_1287_204_0</td>\n",
       "      <td>No :( sadly it doesn't have everything</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>s_1287_222_4</td>\n",
       "      <td>I'm worried.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>s_1287_240_1</td>\n",
       "      <td>Better weapons and going against a weaker team...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          docid                                               TEXT\n",
       "0  s_1287_153_9                          I mean what the hell bro.\n",
       "1  s_1287_187_0                              Yeah, crazy isn't it?\n",
       "2  s_1287_204_0           No :( sadly it doesn't have everything  \n",
       "3  s_1287_222_4                                       I'm worried.\n",
       "4  s_1287_240_1  Better weapons and going against a weaker team..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "clean_ef_data = pd.read_csv('tabulated_cleaned_emotionfiltered_trec.csv')\n",
    "clean_ef_data = clean_ef_data.drop(['polarity', 'self_ref', 'PRE', 'POST'], axis=1)\n",
    "print(\"clean emotion filtered data shape: \", clean_ef_data.shape)\n",
    "clean_ef_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aug answer set shape:  (928, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>Starting tasks requires more work than before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>I’m feeling low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>612</th>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>I feel that my looks are repulsive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>I don’t feel very guilty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Question  Severity                                            Text\n",
       "640        15         2   Starting tasks requires more work than before\n",
       "18          1         2                                 I’m feeling low\n",
       "612        14         4              I feel that my looks are repulsive\n",
       "179         5         1                        I don’t feel very guilty"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load set of augmented answers\n",
    "aug_answer_set = pd.read_csv('augmented_answer_sets.csv')\n",
    "print(\"aug answer set shape: \", aug_answer_set.shape)\n",
    "aug_answer_set.sample(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have answer sets and input text, let's create embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28c6f4f37b0472bae60bec7bb83f5ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create tokens and vector embeddings for user posts\n",
    "post_embeddings_df = clean_ef_data.copy()\n",
    "\n",
    "post_embeddings = post_embeddings_df['TEXT'].to_list()\n",
    "\n",
    "post_embeddings = model.encode(post_embeddings, device='cuda', show_progress_bar=True, \n",
    "                               output_value='sentence_embedding', convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 56.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store the embeddings\n",
    "bdi_embeddings = {}\n",
    "\n",
    "# Loop over all 21 BDI questions\n",
    "for i in tqdm(range(1, 22), total=21):\n",
    "    # Filter the DataFrame for the current question and severity > 1\n",
    "    bdi_i_embedding_df = aug_answer_set[(aug_answer_set['Question'] == i) & (aug_answer_set['Severity'] > 1)]\n",
    "    \n",
    "    # Get embeddings for the filtered DataFrame\n",
    "    bdi_i_embeddings = model.encode(\n",
    "        bdi_i_embedding_df['Text'].to_list(), device='cuda', output_value='sentence_embedding', convert_to_tensor=True\n",
    "    )\n",
    "    \n",
    "    # Store the embeddings in the dictionary\n",
    "    bdi_embeddings[f\"q{i}\"] = bdi_i_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have embeddings for each post and the associated question, we will rank. \n",
    "\n",
    "The rankings will be computed for each question, and are based on the max-similarity \n",
    "\n",
    "between a post's embedding and the embedding array of the corresponding question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/27981 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27981/27981 [00:02<00:00, 9529.72it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9546.19it/s]\n",
      "100%|██████████| 27981/27981 [00:03<00:00, 9059.24it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9518.63it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9543.57it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9541.32it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9539.15it/s]\n",
      "100%|██████████| 27981/27981 [00:03<00:00, 9017.78it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9518.77it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9481.17it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9537.17it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9549.82it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9526.37it/s]\n",
      "100%|██████████| 27981/27981 [00:03<00:00, 9055.51it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9553.51it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9547.82it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9547.42it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9551.87it/s]\n",
      "100%|██████████| 27981/27981 [00:03<00:00, 9098.03it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9459.22it/s]\n",
      "100%|██████████| 27981/27981 [00:02<00:00, 9530.97it/s]\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_dict = {}\n",
    "\n",
    "for i in range(1, 22):\n",
    "\n",
    "    # Get the correct embeddings list by key\n",
    "    qa_embeddings = bdi_embeddings[f\"q{i}\"]\n",
    "\n",
    "    # Get the max cosine similarity between each post embedding and the answer set for the current BDI question\n",
    "    qi_cos_similarities = [\n",
    "        torch.max(cosine_similarity(post_embedding, qa_embeddings)).item()\n",
    "        for post_embedding in tqdm(post_embeddings, total=len(post_embeddings))\n",
    "    ]\n",
    "\n",
    "    # Assign these max cosine similarity rankings to the cosine similarity dictionary\n",
    "    cosine_similarity_dict[f'q{i}'] = qi_cos_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have cosine similarities for each question, we need to assign them post ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 21/21 [00:00<00:00, 143.40it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialize an empty dictionary to store the rankings for each question\n",
    "rankings_dict = {}\n",
    "\n",
    "# Loop over all 21 BDI questions\n",
    "for i in tqdm(range(1, 22), total=21):\n",
    "    # Make a copy of the clean_ef_data DataFrame\n",
    "    q_rankings = clean_ef_data.copy()\n",
    "    \n",
    "    # Add a 'score' column to the DataFrame, which contains the cosine similarity scores for the current question\n",
    "    q_rankings['score'] = cosine_similarity_dict[f'q{i}']\n",
    "    \n",
    "    # Sort the DataFrame by the 'score' column in descending order and reset the index\n",
    "    q_rankings = q_rankings.sort_values('score', ascending=False, ignore_index=True)\n",
    "    \n",
    "    # Keep only the top 1000 rows\n",
    "    q_rankings = q_rankings.head(1000)\n",
    "    \n",
    "    # Store the DataFrame in the rankings_dict dictionary with the key as the current question\n",
    "    rankings_dict[f'q{i}'] = q_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINETUNED VERSION\n",
    "\n",
    "# Format the rankings dict as trec-formatted content before saving to disk.\n",
    "# for i, key in enumerate(rankings_dict.keys()):\n",
    "#     rankings_dict[key]['query'] = f'{i+1}' # create query number\n",
    "#     rankings_dict[key]['q_id'] = rankings_dict[key]['query']\n",
    "#     rankings_dict[key]['doc_id'] = rankings_dict[key]['docid']\n",
    "#     rankings_dict[key]['q0'] = '0'\n",
    "#     rankings_dict[key]['rank'] = range(1, 1001)\n",
    "#     rankings_dict[key]['rank'] = rankings_dict[key]['rank'].astype(str)\n",
    "#     rankings_dict[key]['model'] = 'distilbert-base-uncased-emotion'\n",
    "#     rankings_dict[key] = rankings_dict[key][[\"q_id\", \"q0\", \"doc_id\", \"score\", \"rank\", \"model\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE VERSION\n",
    "# Format the rankings dict as trec-formatted content before saving to disk.\n",
    "for i, key in enumerate(rankings_dict.keys()):\n",
    "    rankings_dict[key]['query'] = f'{i+1}' # create query number\n",
    "    rankings_dict[key]['q_id'] = rankings_dict[key]['query']\n",
    "    rankings_dict[key]['doc_id'] = rankings_dict[key]['docid']\n",
    "    rankings_dict[key]['q0'] = '0'\n",
    "    rankings_dict[key]['rank'] = range(1, 1001)\n",
    "    rankings_dict[key]['rank'] = rankings_dict[key]['rank'].astype(str)\n",
    "    rankings_dict[key]['model'] = 'all-MiniLM-L6-v2'\n",
    "    rankings_dict[key] = rankings_dict[key][[\"q_id\", \"q0\", \"doc_id\", \"score\", \"rank\", \"model\"]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for key, df in rankings_dict.items():\n",
    "#     df.to_csv(f'distilbert-base-uncased-ranking-outputs/{key}_rankings.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate all the DataFrames in the dictionary\n",
    "all_rankings = pd.concat(rankings_dict.values(), ignore_index=True)\n",
    "\n",
    "# # Save the concatenated DataFrame as a TSV file\n",
    "all_rankings.to_csv('minilm_results.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have completed the rankings portion. We need to compare rankings against our qrels to get performance metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the rankings tsv file. It represents top 1000 rankings for each question.\n",
    "minilm_rankings = pd.read_csv(\"minilm_results.tsv\", sep=\"\\t\")\n",
    "minilm_rankings.columns = [\"query\", \"q0\", \"docid\", \"score\", \"rank\", \"model\"]\n",
    "distilbert_rankings = pd.read_csv(\"dbue_results.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2286_168_4</td>\n",
       "      <td>0.891695</td>\n",
       "      <td>1</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_993_781_1</td>\n",
       "      <td>0.836626</td>\n",
       "      <td>2</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_962_142_0</td>\n",
       "      <td>0.799796</td>\n",
       "      <td>3</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_326_265_1</td>\n",
       "      <td>0.791842</td>\n",
       "      <td>4</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2100_761_0</td>\n",
       "      <td>0.770194</td>\n",
       "      <td>5</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2800_37_1</td>\n",
       "      <td>0.319181</td>\n",
       "      <td>996</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_1265_884_4</td>\n",
       "      <td>0.319173</td>\n",
       "      <td>997</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_1030_486_2</td>\n",
       "      <td>0.319138</td>\n",
       "      <td>998</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_3028_163_4</td>\n",
       "      <td>0.319114</td>\n",
       "      <td>999</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2635_397_0</td>\n",
       "      <td>0.319080</td>\n",
       "      <td>1000</td>\n",
       "      <td>all-MiniLM-L6-v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  q0         docid     score  rank             model\n",
       "0          1   0  s_2286_168_4  0.891695     1  all-MiniLM-L6-v2\n",
       "1          1   0   s_993_781_1  0.836626     2  all-MiniLM-L6-v2\n",
       "2          1   0   s_962_142_0  0.799796     3  all-MiniLM-L6-v2\n",
       "3          1   0   s_326_265_1  0.791842     4  all-MiniLM-L6-v2\n",
       "4          1   0  s_2100_761_0  0.770194     5  all-MiniLM-L6-v2\n",
       "...      ...  ..           ...       ...   ...               ...\n",
       "20995     21   0   s_2800_37_1  0.319181   996  all-MiniLM-L6-v2\n",
       "20996     21   0  s_1265_884_4  0.319173   997  all-MiniLM-L6-v2\n",
       "20997     21   0  s_1030_486_2  0.319138   998  all-MiniLM-L6-v2\n",
       "20998     21   0  s_3028_163_4  0.319114   999  all-MiniLM-L6-v2\n",
       "20999     21   0  s_2635_397_0  0.319080  1000  all-MiniLM-L6-v2\n",
       "\n",
       "[21000 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minilm_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_993_781_1</td>\n",
       "      <td>0.997397</td>\n",
       "      <td>1</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2286_168_4</td>\n",
       "      <td>0.997172</td>\n",
       "      <td>2</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_17_843_10</td>\n",
       "      <td>0.994586</td>\n",
       "      <td>3</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_962_142_0</td>\n",
       "      <td>0.993817</td>\n",
       "      <td>4</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2953_456_0</td>\n",
       "      <td>0.992738</td>\n",
       "      <td>5</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20995</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2296_272_0</td>\n",
       "      <td>0.875914</td>\n",
       "      <td>996</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20996</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2504_1011_1</td>\n",
       "      <td>0.875896</td>\n",
       "      <td>997</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20997</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_993_560_3</td>\n",
       "      <td>0.875853</td>\n",
       "      <td>998</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20998</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2459_975_2</td>\n",
       "      <td>0.875849</td>\n",
       "      <td>999</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20999</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2338_771_2</td>\n",
       "      <td>0.875844</td>\n",
       "      <td>1000</td>\n",
       "      <td>distilbert-base-uncased-emotion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       query  q0          docid     score  rank  \\\n",
       "0          1   0    s_993_781_1  0.997397     1   \n",
       "1          1   0   s_2286_168_4  0.997172     2   \n",
       "2          1   0    s_17_843_10  0.994586     3   \n",
       "3          1   0    s_962_142_0  0.993817     4   \n",
       "4          1   0   s_2953_456_0  0.992738     5   \n",
       "...      ...  ..            ...       ...   ...   \n",
       "20995     21   0   s_2296_272_0  0.875914   996   \n",
       "20996     21   0  s_2504_1011_1  0.875896   997   \n",
       "20997     21   0    s_993_560_3  0.875853   998   \n",
       "20998     21   0   s_2459_975_2  0.875849   999   \n",
       "20999     21   0   s_2338_771_2  0.875844  1000   \n",
       "\n",
       "                                 model  \n",
       "0      distilbert-base-uncased-emotion  \n",
       "1      distilbert-base-uncased-emotion  \n",
       "2      distilbert-base-uncased-emotion  \n",
       "3      distilbert-base-uncased-emotion  \n",
       "4      distilbert-base-uncased-emotion  \n",
       "...                                ...  \n",
       "20995  distilbert-base-uncased-emotion  \n",
       "20996  distilbert-base-uncased-emotion  \n",
       "20997  distilbert-base-uncased-emotion  \n",
       "20998  distilbert-base-uncased-emotion  \n",
       "20999  distilbert-base-uncased-emotion  \n",
       "\n",
       "[21000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distilbert_rankings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_405_1279_15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2519_356_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2038_51_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_975_61_2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_577_923_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query  q0          docid  rel\n",
       "0      1   0  s_405_1279_15    1\n",
       "1      1   0   s_2519_356_0    0\n",
       "2      1   0    s_2038_51_7    1\n",
       "3      1   0     s_975_61_2    1\n",
       "4      1   0    s_577_923_1    1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the majority qrels file\n",
    "qrels_majority = pd.read_csv('task1/training/t1_training/TRAINING DATA (2023 COLLECTION)/g_qrels_majority_2.csv')\n",
    "# qrels_majority['query'] = qrels_majority['query'].astype(str)\n",
    "# qrels_majority.columns = [\"q_id\", \"q0\", \"doc_id\", \"score\"]\n",
    "qrels_majority.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>q0</th>\n",
       "      <th>docid</th>\n",
       "      <th>rel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_405_1279_15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2519_356_0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_2038_51_7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_975_61_2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>s_577_923_1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   query  q0          docid  rel\n",
       "0      1   0  s_405_1279_15    1\n",
       "1      1   0   s_2519_356_0    0\n",
       "2      1   0    s_2038_51_7    1\n",
       "3      1   0     s_975_61_2    0\n",
       "4      1   0    s_577_923_1    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the consensus qrels file\n",
    "qrels_consensus = pd.read_csv('task1/training/t1_training/TRAINING DATA (2023 COLLECTION)/g_rels_consenso.csv')\n",
    "# qrels_consensus['query'] = qrels_consensus['query'].astype(str)\n",
    "# qrels_consensus.columns = [\"q_id\", \"q0\", \"doc_id\", \"score\"]\n",
    "qrels_consensus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have qrels and rankings for each question, let's calculate the retrieval effectiveness metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_ndcg_at_1000_per_query(ranked_docs, qrels):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Discounted Cumulative Gain (NDCG) at 1000 for each query in a DataFrame of ranked documents.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_docs (DataFrame): A DataFrame with columns 'quer', 'q0', 'docid', 'score', 'rank', and 'model', representing the ranked documents.\n",
    "    qrels (DataFrame): A DataFrame with columns 'docid' and 'rel', mapping documents to their true relevance (1 if the document is relevant, 0 otherwise).\n",
    "\n",
    "    Returns:\n",
    "    list: A list of NDCG@1000 values for each query.\n",
    "    \"\"\"\n",
    "    # Convert qrels DataFrame to dictionary for faster lookup\n",
    "    qrels_dict = dict(zip(qrels['docid'], qrels['rel']))\n",
    "\n",
    "    # Group the ranked documents by query\n",
    "    grouped = ranked_docs.groupby('query')\n",
    "\n",
    "    # Initialize a list to store the NDCG@1000 values\n",
    "    ndcg_values = []\n",
    "\n",
    "    # Loop over the groups\n",
    "    for name, group in grouped:\n",
    "        # Initialize a list to store the relevance scores for this group\n",
    "        relevance_scores = []\n",
    "\n",
    "        # Loop over the documents in this group\n",
    "        for doc in group['docid']:\n",
    "            # If the document is in the qrels file and is relevant, append 1 to the relevance scores\n",
    "            if doc in qrels_dict and qrels_dict[doc] == 1:\n",
    "                relevance_scores.append(1)\n",
    "            # Otherwise, append 0 to the relevance scores\n",
    "            else:\n",
    "                relevance_scores.append(0)\n",
    "\n",
    "        # Compute the NDCG@1000 for this group\n",
    "        ndcg = ndcg_score(np.asarray([relevance_scores]), np.asarray([relevance_scores]), k=1000)\n",
    "\n",
    "        # Append the NDCG@1000 to the list of NDCG@1000 values\n",
    "        ndcg_values.append(ndcg)\n",
    "\n",
    "    return ndcg_values\n",
    "\n",
    "# Run it on the results for consensus and majority\n",
    "distilbert_ndcg_at_1000_consensus = calculate_ndcg_at_1000_per_query(distilbert_rankings, qrels_consensus)\n",
    "distilbert_ndcg_at_1000_majority = calculate_ndcg_at_1000_per_query(distilbert_rankings, qrels_majority)\n",
    "minilm_ndcg_at_1000_consensus = calculate_ndcg_at_1000_per_query(minilm_rankings, qrels_consensus)\n",
    "minilm_ndcg_at_1000_majority = calculate_ndcg_at_1000_per_query(minilm_rankings, qrels_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_precision_at_10_per_query(ranked_docs, qrels):\n",
    "    \"\"\"\n",
    "    Calculate the Precision at 10 for each query in the BDI question set.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_docs (DataFrame): A DataFrame with columns 'query', 'q0', 'docid', 'score', 'rank', and 'model', representing the ranked documents.\n",
    "    qrels (DataFrame): A DataFrame with columns 'docid' and 'rel', mapping documents to their true relevance (1 if the document is relevant, 0 otherwise).\n",
    "\n",
    "    Returns:\n",
    "    list: A list of Precision@10 values for each query.\n",
    "    \"\"\"\n",
    "    # Convert qrels DataFrame to dictionary for faster lookup\n",
    "    qrels_dict = dict(zip(qrels['docid'], qrels['rel']))\n",
    "\n",
    "    # Group the ranked documents by query\n",
    "    grouped = ranked_docs.groupby('query')\n",
    "\n",
    "    # Initialize a list to store the Precision@10 values\n",
    "    precision_values = []\n",
    "\n",
    "    # Loop over the groups\n",
    "    for name, group in grouped:\n",
    "        # Initialize a counter for the number of relevant documents\n",
    "        relevant_docs = 0\n",
    "\n",
    "        # Loop over the top 10 documents in this group\n",
    "        for doc in group['docid'][:10]:\n",
    "            # If the document is in the qrels file and is relevant, increment the counter\n",
    "            if doc in qrels_dict and qrels_dict[doc] == 1:\n",
    "                relevant_docs += 1\n",
    "\n",
    "        # Compute the Precision@10 for this group\n",
    "        precision = relevant_docs / 10\n",
    "\n",
    "        # Append the Precision@10 to the list of Precision@10 values\n",
    "        precision_values.append(precision)\n",
    "\n",
    "    return precision_values\n",
    "\n",
    "# Run it on the results for consensus and majority\n",
    "distilbert_precision_at_10_consensus = calculate_precision_at_10_per_query(distilbert_rankings, qrels_consensus)\n",
    "distilbert_precision_at_10_majority = calculate_precision_at_10_per_query(distilbert_rankings, qrels_majority)\n",
    "minilm_precision_at_10_consensus = calculate_precision_at_10_per_query(minilm_rankings, qrels_consensus)\n",
    "minilm_precision_at_10_majority = calculate_precision_at_10_per_query(minilm_rankings, qrels_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_map_per_query(ranked_docs, qrels):\n",
    "    \"\"\"\n",
    "    Calculate the Mean Average Precision (MAP) for each query in a DataFrame of ranked documents.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_docs (DataFrame): A DataFrame with columns 'q_id', 'q0', 'doc_id', 'score', 'rank', and 'model', representing the ranked documents.\n",
    "    qrels (DataFrame): A DataFrame with columns 'docid' and 'rel', mapping documents to their true relevance (1 if the document is relevant, 0 otherwise).\n",
    "\n",
    "    Returns:\n",
    "    list: A list of MAP values for each query.\n",
    "    \"\"\"\n",
    "    # Convert qrels DataFrame to dictionary for faster lookup\n",
    "    qrels_dict = dict(zip(qrels['docid'], qrels['rel']))\n",
    "\n",
    "    # Group the ranked documents by query\n",
    "    grouped = ranked_docs.groupby('query')\n",
    "\n",
    "    # Initialize a list to store the average precision values\n",
    "    avg_precision_values = []\n",
    "\n",
    "    # Loop over the groups\n",
    "    for name, group in grouped:\n",
    "        # Initialize a counter for the number of relevant documents and a list to store the precision values\n",
    "        relevant_docs = 0\n",
    "        precision_values = []\n",
    "\n",
    "        # Loop over the documents in this group\n",
    "        for i, doc in enumerate(group['docid']):\n",
    "            # If the document is in the qrels file and is relevant, increment the counter and compute the precision\n",
    "            if doc in qrels_dict and qrels_dict[doc] == 1:\n",
    "                relevant_docs += 1\n",
    "                precision = relevant_docs / (i + 1)\n",
    "                precision_values.append(precision)\n",
    "\n",
    "        # Compute the average precision for this group\n",
    "        avg_precision = sum(precision_values) / len(precision_values) if precision_values else 0\n",
    "\n",
    "        # Append the average precision to the list of average precision values\n",
    "        avg_precision_values.append(avg_precision)\n",
    "\n",
    "    return avg_precision_values\n",
    "\n",
    "# Run it on the results for consensus and majority\n",
    "distilbert_map_consensus = calculate_map_per_query(distilbert_rankings, qrels_consensus)\n",
    "distilbert_map_majority = calculate_map_per_query(distilbert_rankings, qrels_majority)\n",
    "minilm_map_consensus = calculate_map_per_query(minilm_rankings, qrels_consensus)\n",
    "minilm_map_majority = calculate_map_per_query(minilm_rankings, qrels_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_r_precision_per_query(ranked_docs, qrels):\n",
    "    \"\"\"\n",
    "    Calculate the R-Precision for each query in a DataFrame of ranked documents.\n",
    "\n",
    "    Parameters:\n",
    "    ranked_docs (DataFrame): A DataFrame with columns 'q_id', 'q0', 'doc_id', 'score', 'rank', and 'model', representing the ranked documents.\n",
    "    qrels (DataFrame): A DataFrame with columns 'docid' and 'rel', mapping documents to their true relevance (1 if the document is relevant, 0 otherwise).\n",
    "\n",
    "    Returns:\n",
    "    list: A list of R-Precision values for each query.\n",
    "    \"\"\"\n",
    "    # Convert qrels DataFrame to dictionary for faster lookup\n",
    "    qrels_dict = dict(zip(qrels['docid'], qrels['rel']))\n",
    "\n",
    "    # Group the ranked documents by query\n",
    "    grouped = ranked_docs.groupby('query')\n",
    "\n",
    "    # Initialize a list to store the R-Precision values\n",
    "    r_precision_values = []\n",
    "\n",
    "    # Loop over the groups\n",
    "    for name, group in grouped:\n",
    "        # Count the number of relevant documents for this query\n",
    "        r = sum(1 for doc in group['docid'] if doc in qrels_dict and qrels_dict[doc] == 1)\n",
    "\n",
    "        # Initialize a counter for the number of relevant documents in the top R\n",
    "        relevant_docs_in_top_r = 0\n",
    "\n",
    "        # Loop over the top R documents in this group\n",
    "        for doc in group['docid'][:r]:\n",
    "            # If the document is in the qrels file and is relevant, increment the counter\n",
    "            if doc in qrels_dict and qrels_dict[doc] == 1:\n",
    "                relevant_docs_in_top_r += 1\n",
    "\n",
    "        # Compute the R-Precision for this group\n",
    "        r_precision = relevant_docs_in_top_r / r if r > 0 else 0\n",
    "\n",
    "        # Append the R-Precision to the list of R-Precision values\n",
    "        r_precision_values.append(r_precision)\n",
    "\n",
    "    return r_precision_values\n",
    "\n",
    "# Run it on the results for consensus and majority\n",
    "distilbert_r_precision_consensus = calculate_r_precision_per_query(distilbert_rankings, qrels_consensus)\n",
    "distilbert_r_precision_majority = calculate_r_precision_per_query(distilbert_rankings, qrels_majority)\n",
    "minilm_r_precision_consensus = calculate_r_precision_per_query(minilm_rankings, qrels_consensus)\n",
    "minilm_r_precision_majority = calculate_r_precision_per_query(minilm_rankings, qrels_majority)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create four dataframes to store evaluation metrics : minilm and distilbert for consensus and majority\n",
    "distilbert_consensus_metrics = pd.DataFrame({\n",
    "    \"NDCG@1000\": distilbert_ndcg_at_1000_consensus,\n",
    "    \"Precision@10\": distilbert_precision_at_10_consensus,\n",
    "    \"MAP\": distilbert_map_consensus,\n",
    "    \"R-Precision\": distilbert_r_precision_consensus\n",
    "})\n",
    "distilbert_majority_metrics = pd.DataFrame({\n",
    "    \"NDCG@1000\": distilbert_ndcg_at_1000_majority,\n",
    "    \"Precision@10\": distilbert_precision_at_10_majority,\n",
    "    \"MAP\": distilbert_map_majority,\n",
    "    \"R-Precision\": distilbert_r_precision_majority\n",
    "})\n",
    "minilm_consensus_metrics = pd.DataFrame({\n",
    "    \"NDCG@1000\": minilm_ndcg_at_1000_consensus,\n",
    "    \"Precision@10\": minilm_precision_at_10_consensus,\n",
    "    \"MAP\": minilm_map_consensus,\n",
    "    \"R-Precision\": minilm_r_precision_consensus\n",
    "})\n",
    "minilm_majority_metrics = pd.DataFrame({\n",
    "    \"NDCG@1000\": minilm_ndcg_at_1000_majority,\n",
    "    \"Precision@10\": minilm_precision_at_10_majority,\n",
    "    \"MAP\": minilm_map_majority,\n",
    "    \"R-Precision\": minilm_r_precision_majority\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make a plot of distilbert precision@10 vs minilm precision@10 for majority\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Create an array with the position of each bar along the x-axis\n",
    "x = np.arange(1, len(distilbert_majority_metrics[\"Precision@10\"])+1)\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(x - 0.2, distilbert_majority_metrics[\"Precision@10\"], 0.4, label=\"DistilBERT\")\n",
    "plt.bar(x + 0.2, minilm_majority_metrics[\"Precision@10\"], 0.4, label=\"MiniLM\")\n",
    "\n",
    "# Define the labels and title\n",
    "plt.xlabel(\"Query\")\n",
    "plt.ylabel(\"Precision@10\")\n",
    "\n",
    "# Set the x-ticks to be every integer from 1 through 21\n",
    "plt.xticks(np.arange(1, 22))\n",
    "\n",
    "# Add the legend\n",
    "plt.legend()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.016930816485313124, 0.09757065809037589]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get p-values for differences in p@10 between distilbert and minilm\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "p_values = [ttest_rel(distilbert_majority_metrics[\"Precision@10\"], minilm_majority_metrics[\"Precision@10\"]).pvalue,\n",
    "            ttest_rel(distilbert_consensus_metrics[\"Precision@10\"], minilm_consensus_metrics[\"Precision@10\"]).pvalue]\n",
    "\n",
    "p_values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
